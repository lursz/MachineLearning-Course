{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import pickle\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "mnist.target = mnist.target.astype(np.uint8)\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  8 silhouette score =  0.07338673784143673\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m y_pred \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mpredict(X)\n\u001b[1;32m     14\u001b[0m \u001b[39m# ----------------------------- Silhouette score ----------------------------- #\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m temp_silhouette_score \u001b[39m=\u001b[39m silhouette_score(X, y_pred)\n\u001b[1;32m     16\u001b[0m silhouette_list\u001b[39m.\u001b[39mappend(silhouette_score(X, kmeans\u001b[39m.\u001b[39mlabels_))\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mk = \u001b[39m\u001b[39m\"\u001b[39m, i, \u001b[39m\"\u001b[39m\u001b[39msilhouette score = \u001b[39m\u001b[39m\"\u001b[39m, silhouette_list[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/metrics/cluster/_unsupervised.py:117\u001b[0m, in \u001b[0;36msilhouette_score\u001b[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         X, labels \u001b[39m=\u001b[39m X[indices], labels[indices]\n\u001b[0;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(silhouette_samples(X, labels, metric\u001b[39m=\u001b[39;49mmetric, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/metrics/cluster/_unsupervised.py:237\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    233\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m metric\n\u001b[1;32m    234\u001b[0m reduce_func \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m    235\u001b[0m     _silhouette_reduce, labels\u001b[39m=\u001b[39mlabels, label_freqs\u001b[39m=\u001b[39mlabel_freqs\n\u001b[1;32m    236\u001b[0m )\n\u001b[0;32m--> 237\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mpairwise_distances_chunked(X, reduce_func\u001b[39m=\u001b[39;49mreduce_func, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    238\u001b[0m intra_clust_dists, inter_clust_dists \u001b[39m=\u001b[39m results\n\u001b[1;32m    239\u001b[0m intra_clust_dists \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(intra_clust_dists)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1867\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1866\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[0;32m-> 1867\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39;49mmetric, n_jobs\u001b[39m=\u001b[39;49mn_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1868\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1869\u001b[0m     metric, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m ) \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   1871\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[1;32m   1872\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[1;32m   1873\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart :: _num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:2039\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[1;32m   2037\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 2039\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1579\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1576\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1578\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1579\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1581\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1582\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:300\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meuclidean_distances\u001b[39m(\n\u001b[1;32m    225\u001b[0m     X, Y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, Y_norm_squared\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, squared\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, X_norm_squared\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    226\u001b[0m ):\n\u001b[1;32m    227\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39m    Compute the distance matrix between each pair from a vector array X and Y.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39m           [1.41421356]])\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m    302\u001b[0m     \u001b[39mif\u001b[39;00m X_norm_squared \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m         X_norm_squared \u001b[39m=\u001b[39m check_array(X_norm_squared, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:163\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    156\u001b[0m         X,\n\u001b[1;32m    157\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[0;32m--> 163\u001b[0m     Y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    164\u001b[0m         Y,\n\u001b[1;32m    165\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    166\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    167\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    168\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    169\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m precomputed:\n\u001b[1;32m    173\u001b[0m     \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from statistics import mode\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_list = []\n",
    "cm = 0\n",
    "\n",
    "# Clusters from 8 to 12\n",
    "for i in range(8, 13):\n",
    "    kmeans = KMeans(n_clusters=i, n_init=10)\n",
    "    kmeans.fit(X)\n",
    "    y_pred = kmeans.predict(X)\n",
    "    \n",
    "    # ----------------------------- Silhouette score ----------------------------- #\n",
    "    temp_silhouette_score = silhouette_score(X, y_pred)\n",
    "    silhouette_list.append(silhouette_score(X, kmeans.labels_))\n",
    "    print(\"k = \", i, \"silhouette score = \", silhouette_list[-1])\n",
    "    \n",
    "        \n",
    "    # ----------------------------- Confusion matrix ----------------------------- #\n",
    "    if i == 10:\n",
    "        cm = confusion_matrix(y, y_pred)\n",
    "        print(\"k = \", i, \"confusion matrix = \\n\", cm)\n",
    "\n",
    "with open(\"kmeans_sil.pkl\", \"wb\") as f:\n",
    "    pickle.dump(silhouette_list, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find index of max value for every row\n",
    "max_indices = np.argmax(cm, axis=1)\n",
    "max_indices_sorted = sorted(set(max_indices))\n",
    "\n",
    "# save to pickle\n",
    "with open(\"kmeans_argmax.pkl\", \"wb\") as f:\n",
    "    pickle.dump(max_indices_sorted, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances =  [279.26152617 304.3764117  317.5893575  328.76587414 333.45464459\n",
      " 352.89800226 355.17742045 358.0740147  359.64287842 360.42474943]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Calculate the distances for the first 300 elements in X with all the other elements in X\n",
    "distances = np.array([np.linalg.norm(X[i] - X[j]) for i in range(300) for j in range(len(X))])\n",
    "distances = [i for i in distances if i != 0]\n",
    "\n",
    "# 10 smallest distances\n",
    "distances = np.sort(distances)[:10]\n",
    "\n",
    "with open(\"dist.pkl\", \"wb\") as f:\n",
    "    pickle.dump(list(distances), f)\n",
    "\n",
    "print(\"distances = \", distances)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300.40909845916684\n",
      "[300.40909846 312.4254624  324.44182634]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Calculate the average s of the 3 smallest values from the list\n",
    "s = np.mean(distances[:3])\n",
    "print(s)\n",
    "\n",
    "# Take eps values from s to s+10%*s with a step of 4%*s\n",
    "eps_min = s\n",
    "eps_max = s + 0.1 * s\n",
    "eps_step = 0.04 * s\n",
    "eps_values = np.arange(eps_min, eps_max, eps_step)\n",
    "print(eps_values)\n",
    "\n",
    "# Perform clustering \n",
    "for eps in eps_values:\n",
    "    dbscan = DBSCAN(eps=eps)\n",
    "    dbscan.fit(X)\n",
    "    labels = dbscan.labels_\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7, 22]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Create an empty list to store the values\n",
    "label_list = []\n",
    "\n",
    "# Perform clustering for each eps value\n",
    "for eps in eps_values:\n",
    "    dbscan = DBSCAN(eps=eps)\n",
    "    dbscan.fit(X)\n",
    "    # Count the number of unique labels\n",
    "    n_labels = len(np.unique(dbscan.labels_))\n",
    "    # Append the value to the list\n",
    "    label_list.append(n_labels)\n",
    "\n",
    "# label list\n",
    "with open(\"dbscan_len.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_list, f)\n",
    "print(label_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
